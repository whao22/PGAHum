{
  "model": {
    "desc": null,
    "value": {
      "nerf": {
        "D": 8,
        "W": 256,
        "d_in": 4,
        "skips": [
          4
        ],
        "multires": 10,
        "d_in_view": 3,
        "output_ch": 4,
        "use_viewdirs": true,
        "multires_view": 4
      },
      "nets_path": "data/pretrained/humannerf/zju_mocap/377/latest.tar",
      "non_rigid": {
        "skips": [
          4
        ],
        "i_embed": 0,
        "multires": 6,
        "mlp_depth": 6,
        "mlp_width": 128,
        "kick_in_iter": 10000,
        "full_band_iter": 50000,
        "condition_code_size": 69
      },
      "offset_net": {
        "D": 6,
        "W": 128,
        "d_in": 3,
        "skips": [
          4
        ],
        "multires": 6,
        "output_ch": 3
      },
      "sdf_network": {
        "bias": 0.5,
        "d_in": 3,
        "d_out": 257,
        "scale": 1,
        "skip_in": [
          4
        ],
        "d_hidden": 256,
        "multires": 16,
        "n_layers": 8,
        "weight_norm": true,
        "geometric_init": true
      },
      "pose_refiner": {
        "mlp_depth": 4,
        "mlp_width": 256,
        "kick_in_iter": 10000,
        "embedding_size": 69
      },
      "neus_renderer": {
        "perturb": 1,
        "n_outside": 0,
        "n_samples": 64,
        "is_adasamp": true,
        "n_importance": 0,
        "use_init_sdf": false,
        "N_iter_backward": 0,
        "up_sample_steps": 4
      },
      "cano_view_dirs": false,
      "decoder_kwargs": {
        "use_FiLM": true,
        "hyper_in_ch": 144,
        "in_features": 3,
        "geometry_net": "data/pretrained/meta-avatar/conv-unet-plane64x3_CAPE-SV_keep-aspect_stage2-inner-1e-6-outer-1e-6_1gpus/model_best.pt",
        "hierarchical_pose": true,
        "num_hidden_layers": 5
      },
      "skinning_model": {
        "bias": 1,
        "d_in": 3,
        "d_out": 25,
        "cond_in": [],
        "skip_in": [],
        "d_hidden": 128,
        "multires": 0,
        "n_layers": 4,
        "weight_norm": true,
        "geometric_init": false,
        "optim_skinning_net_path": "data/pretrained/meta-avatar/conv-unet-plane64x3-shallow-hierarchical_CAPE_keep-aspect_stage0-meta-fwd_batch-size-4_1gpus/model_best.pt"
      },
      "geo_pose_encoder": "latent",
      "sdf_network_high": {
        "bias": 0.5,
        "d_in": 3,
        "d_out": 257,
        "scale": 1,
        "skip_in": [
          4
        ],
        "d_hidden": 256,
        "multires": 16,
        "n_layers": 8,
        "weight_norm": true,
        "geometric_init": false
      },
      "variance_network": {
        "init_val": 0.3
      },
      "rendering_network": {
        "d_in": 9,
        "mode": "idr",
        "d_out": 3,
        "d_hidden": 256,
        "n_layers": 4,
        "d_feature": 256,
        "squeeze_out": true,
        "weight_norm": true,
        "multires_view": 6
      },
      "color_pose_encoder": "latent",
      "far_surface_samples": 16,
      "near_surface_samples": 16
    }
  },
  "train": {
    "desc": null,
    "value": {
      "lr": 0.0005,
      "gpus": [
        0
      ],
      "weights": {
        "rgb_weight": 10,
        "mask_weight": 0,
        "params_weight": 200,
        "eikonal_weight": 0.01,
        "skinning_weight": 0,
        "perceptual_weight": 1
      },
      "sdf_mode": "mlp",
      "anneal_end": 50000,
      "batch_size": 1,
      "max_epochs": 500,
      "num_workers": 16,
      "warm_up_end": 5000,
      "nv_noise_type": "rotation",
      "rgb_loss_type": "l1",
      "log_every_step": 1,
      "val_every_step": 100,
      "val_every_epoch": 5,
      "lr_non_rigid_mlp": 0.00005,
      "pose_input_noise": true,
      "resolution_level": 4,
      "save_every_epoch": 20,
      "view_input_noise": true,
      "lr_skinning_model": 0.0001,
      "lr_sdf_decoder_net": 0.000001,
      "lr_sdf_decoder_pose_encoder": 0.0001
    }
  },
  "_wandb": {
    "desc": null,
    "value": {
      "m": [
        {
          "1": "trainer/global_step",
          "6": [
            3
          ]
        },
        {
          "1": "loss_color",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss_mask",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss_eikonal",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss_pips",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss_skinning_weights",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss_params",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "loss",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "lr",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "epoch",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples._type",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.width",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.height",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.format",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.count",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.filenames",
          "5": 1,
          "6": [
            1
          ]
        },
        {
          "1": "validation_samples.captions",
          "5": 1,
          "6": [
            1
          ]
        }
      ],
      "t": {
        "1": [
          1,
          9,
          41,
          55
        ],
        "3": [
          7,
          13,
          16
        ],
        "4": "3.9.7",
        "5": "0.12.15",
        "8": [
          5
        ]
      },
      "framework": "lightning",
      "start_time": 1701793556,
      "cli_version": "0.12.15",
      "is_jupyter_run": false,
      "python_version": "3.9.7",
      "is_kaggle_kernel": false
    }
  },
  "dataset": {
    "desc": null,
    "value": {
      "dim": 3,
      "dataset": "zju_mocap",
      "use_aug": false,
      "N_frames": 616,
      "data_dir": "data/data_prepared",
      "N_patches": 2,
      "val_split": [
        "CoreView_377"
      ],
      "val_views": [
        0
      ],
      "box_margin": 0.05,
      "erode_mask": false,
      "patch_size": 64,
      "test_split": [
        "CoreView_377"
      ],
      "test_views": [
        0
      ],
      "train_split": [
        "CoreView_377"
      ],
      "train_views": [
        0
      ],
      "val_end_frame": -1,
      "inner_sampling": false,
      "ray_shoot_mode": "patch",
      "test_end_frame": -1,
      "train_end_frame": 500,
      "val_start_frame": 500,
      "backgroung_color": [
        "0.",
        "0.",
        "0."
      ],
      "normalized_scale": true,
      "resize_img_scale": 1,
      "test_start_frame": 500,
      "train_start_frame": 0,
      "sample_subject_ratio": 0.8,
      "val_subsampling_rate": 200,
      "test_subsampling_rate": 100,
      "train_subsampling_rate": 1
    }
  },
  "general": {
    "desc": null,
    "value": {
      "recording": [
        "./"
      ],
      "total_bones": 24,
      "base_exp_dir": "exp/CoreView_377_1701793453_slurm_w/o_inner-w/o_init_sdf"
    }
  }
}